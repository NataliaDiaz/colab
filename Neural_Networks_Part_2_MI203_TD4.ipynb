{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks Part 2 MI203 TD4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NataliaDiaz/colab/blob/master/Neural_Networks_Part_2_MI203_TD4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oevBPEjs-ebR",
        "colab_type": "text"
      },
      "source": [
        "# TP optimisation d'un réseau de neurones\n",
        "\n",
        "L'objectif de ce TP est de manipuler les notions liées à l'optimisation de réseau de neurones.\n",
        "\n",
        "L'idée est de partir d'un code qui fonctionne avec torch (torch faisant toute l'optimisation) et d'essayer de supprimer un maximum de fonction de torch.\n",
        "\n",
        "**CEPENDANT, si vous n'avez pas fini le précédent TP, il est préférable de le terminer (convolution / pooling) plutôt que de commencer celui ci**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkYSIs-uh_ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def visualize_current_model_behaviour(X,Y,model):\n",
        "    grid = np.ones((50,50,3),dtype=int)*255\n",
        "    \n",
        "    batch = np.zeros((50*50,2),dtype=float)\n",
        "    for row in range(50):\n",
        "        for col in range(50):\n",
        "            batch[row*50+col][0]=row\n",
        "            batch[row*50+col][1]=col\n",
        "    prediction = model.getPredictedClass(batch)\n",
        "    \n",
        "    pred = np.ones((50,50,3),dtype=int)*255\n",
        "    for row in range(50):\n",
        "        for col in range(50):\n",
        "            if prediction[row*50+col] == 1:\n",
        "                grid[row][col][0]=175\n",
        "                grid[row][col][2]=175\n",
        "            else:\n",
        "                grid[row][col][0]=175\n",
        "                grid[row][col][1]=175\n",
        "    \n",
        "    for i in range(X.shape[0]):\n",
        "        row,col = X[i][0],X[i][1]\n",
        "        if Y[i]==1:\n",
        "            grid[row][col][0]=0\n",
        "            grid[row][col][2]=0\n",
        "        else:\n",
        "            grid[row][col][0]=0\n",
        "            grid[row][col][1]=0\n",
        "    \n",
        "    return grid\n",
        "\n",
        "\n",
        "def train_test_deep_network(X,Y,model,nbIteration):\n",
        "    model.updateweights((X,Y))\n",
        "\n",
        "    for iteration in range(nbIteration-1):\n",
        "        loss = model.updateweights((X,Y))\n",
        "        \n",
        "        if iteration%50==0:\n",
        "          visu = visualize_current_model_behaviour(X,Y,model)\n",
        "\n",
        "          clear_output()\n",
        "          plt.imshow(visu)\n",
        "          plt.show()\n",
        "          sleep(3)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def getPredictedClass(self,x):\n",
        "        variablex = torch.autograd.Variable(torch.Tensor(x.astype(float)))\n",
        "        variableoutput = self.forward(variablex)\n",
        "        prob = variableoutput.cpu().data.numpy()\n",
        "        return np.argmax(prob,axis=1)\n",
        "    \n",
        "    def updateweights(self,batchfromtrain):\n",
        "        x,y = batchfromtrain\n",
        "        variablex = torch.autograd.Variable(torch.Tensor(x.astype(float)))\n",
        "        variabley = torch.autograd.Variable(torch.from_numpy(y).long())\n",
        "        variableoutput = self.forward(variablex)\n",
        "        \n",
        "        loss = self.losslayer(variableoutput,variabley)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()        \n",
        "        return loss.cpu().data.numpy()\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 30, bias=True)\n",
        "        self.fc2 = nn.Linear(30, 30, bias=True)\n",
        "        self.fc2bis = nn.Linear(30, 30, bias=True)\n",
        "        self.fc3 = nn.Linear(30, 2, bias=True)\n",
        "        \n",
        "        self.train()\n",
        "        \n",
        "        \n",
        "        self.lr = 0.1\n",
        "        self.momentum = 0.5\n",
        "        self.optimizer = optim.SGD(self.parameters(), lr=self.lr, momentum=self.momentum)\n",
        "        self.losslayer = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x/30))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc2bis(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNw7ge7GBWuM",
        "colab_type": "text"
      },
      "source": [
        "ci dessus un exemple de code d'apprentissage : tout est fait dans la fonction model.updateweights((X,Y))\n",
        "\n",
        "notamment, dans les 3 lignes de code \n",
        "self.optimizer.zero_grad()\n",
        "loss.backward()\n",
        "self.optimizer.step()    \n",
        "\n",
        "ci dessous, un exemple de comment on s'en sert sur des données\n",
        "\n",
        "Penser aussi à jeter un coup d'oeil à https://playground.tensorflow.org qui fait globalement la même chose que le code ci dessus mais en beaucoup mieux et en beaucoup plus beau\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjba31Gc_5VL",
        "colab_type": "code",
        "outputId": "9129549e-afd6-4563-c6bd-3bf6eab19cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "model = Net()\n",
        "\n",
        "Y = np.array([1,1,1,1,1,1,1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,1,1,1])\n",
        "Y = np.maximum(Y,np.zeros(Y.shape[0]))\n",
        "X = np.zeros((Y.shape[0],2),dtype=int)\n",
        "X[ 1 ]=np.array([ 2 , 22 ])\n",
        "X[ 2 ]=np.array([ 2 , 37 ])\n",
        "X[ 3 ]=np.array([ 7 , 17 ])\n",
        "X[ 4 ]=np.array([ 7 , 22 ])\n",
        "X[ 5 ]=np.array([ 7 , 32 ])\n",
        "X[ 6 ]=np.array([ 12 , 7 ])\n",
        "X[ 7 ]=np.array([ 12 , 12 ])\n",
        "X[ 8 ]=np.array([ 12 , 22 ])\n",
        "X[ 9 ]=np.array([ 12 , 37 ])\n",
        "X[ 10 ]=np.array([ 17 , 7 ])\n",
        "X[ 11 ]=np.array([ 17 , 22 ])\n",
        "X[ 12 ]=np.array([ 17 , 27 ])\n",
        "X[ 13 ]=np.array([ 17 , 37 ])\n",
        "X[ 14 ]=np.array([ 22 , 17 ])\n",
        "X[ 15 ]=np.array([ 27 , 17 ])\n",
        "X[ 16 ]=np.array([ 27 , 22 ])\n",
        "X[ 17 ]=np.array([ 27 , 27 ])\n",
        "X[ 18 ]=np.array([ 27 , 37 ])\n",
        "X[ 19 ]=np.array([ 32 , 22 ])\n",
        "X[ 20 ]=np.array([ 32 , 32 ])\n",
        "X[ 21 ]=np.array([ 32 , 37 ])\n",
        "X[ 22 ]=np.array([ 37 , 12 ])\n",
        "X[ 23 ]=np.array([ 37 , 17 ])\n",
        "X[ 24 ]=np.array([ 37 , 22 ])\n",
        "X[ 25 ]=np.array([ 37 , 27 ])\n",
        "X[ 26 ]=np.array([ 37 , 37 ])\n",
        "X[ 27 ]=np.array([ 42 , 22 ])\n",
        "X[ 28 ]=np.array([ 42 , 27 ])\n",
        "X[ 29 ]=np.array([ 42 , 32 ])\n",
        "X[ 30 ]=np.array([ 42 , 37 ])\n",
        "\n",
        "\n",
        "train_test_deep_network(X,Y,model,300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2KVGGHapEf8PZTXDuASiFBAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3GRCMQSEvTD",
        "colab_type": "text"
      },
      "source": [
        "**L'objectif de ce TP est de coder vous même : loss.backward() et self.optimizer.step()**\n",
        "\n",
        "Penser à vous aider de la documentation https://pytorch.org/ et de numpy !\n",
        "\n",
        "**IMPORTANT :**\n",
        "\n",
        "les couches sont donc désormais des objets numpy !\n",
        "\n",
        "la loss ne peut plus être une cross entropy... à la place, utiliser la hingeloss : loss = model.relu(1-y*(proba_classe_1-proba_classe_0))\n",
        "\n",
        "ne chercher pas à visualiser en même temps que vous calculer (c'est déjà assez compliqué) - chercher juste à diminuer la loss\n",
        "\n",
        "**coder l'optimisation dans la cellule \"NET\" puis lancer (plusieurs fois d'affiler) la cellule d'après - la loss doit diminuer - chaque lancer correspond à 10 pas de gradient**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hl1fWvSGMiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable\n",
        "\n",
        "import collections \n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def updateweights(self,batch):\n",
        "        allX,allY = batch\n",
        "        allX,allY = shuffle(allX,allY)\n",
        "        totalloss = 0\n",
        "        \n",
        "        for sample in range(len(allX)):\n",
        "            x = allX[sample].copy()\n",
        "            y = allY[sample].copy()\n",
        "        \n",
        "            print(\"TODO\")\n",
        "    \n",
        "        return totalloss\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = np.random.randn(30,2)\n",
        "        self.fc1bias = np.random.randn(30)\n",
        "        \n",
        "        self.fc2 = np.random.randn(30,30)\n",
        "        self.fc2bias = np.random.randn(30)\n",
        "        \n",
        "        self.fc2bis = np.random.randn(30,30)\n",
        "        self.fc2biasbis = np.random.randn(30)\n",
        "        \n",
        "        self.fc3 = np.random.randn(2,30)\n",
        "        self.fc3bias = np.random.randn(2)\n",
        "        \n",
        "        self.w = [self.fc1,self.fc2,self.fc2bis,self.fc3]\n",
        "        self.b = [self.fc1bias,self.fc2bias,self.fc2biasbis,self.fc3bias]\n",
        "\n",
        "    def leaky_relu(self,v):\n",
        "        if v>0:\n",
        "            return v\n",
        "        else:\n",
        "            return v/100\n",
        "    def relu(self,v):\n",
        "        if v>0:\n",
        "            return v\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "model = Net()\n",
        "\n",
        "Y = np.array([1,1,1,1,1,1,1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,1,-1,1,1,1,1])\n",
        "Y = np.maximum(Y,np.zeros(Y.shape[0]))\n",
        "X = np.zeros((Y.shape[0],2),dtype=int)\n",
        "X[ 1 ]=np.array([ 2 , 22 ])\n",
        "X[ 2 ]=np.array([ 2 , 37 ])\n",
        "X[ 3 ]=np.array([ 7 , 17 ])\n",
        "X[ 4 ]=np.array([ 7 , 22 ])\n",
        "X[ 5 ]=np.array([ 7 , 32 ])\n",
        "X[ 6 ]=np.array([ 12 , 7 ])\n",
        "X[ 7 ]=np.array([ 12 , 12 ])\n",
        "X[ 8 ]=np.array([ 12 , 22 ])\n",
        "X[ 9 ]=np.array([ 12 , 37 ])\n",
        "X[ 10 ]=np.array([ 17 , 7 ])\n",
        "X[ 11 ]=np.array([ 17 , 22 ])\n",
        "X[ 12 ]=np.array([ 17 , 27 ])\n",
        "X[ 13 ]=np.array([ 17 , 37 ])\n",
        "X[ 14 ]=np.array([ 22 , 17 ])\n",
        "X[ 15 ]=np.array([ 27 , 17 ])\n",
        "X[ 16 ]=np.array([ 27 , 22 ])\n",
        "X[ 17 ]=np.array([ 27 , 27 ])\n",
        "X[ 18 ]=np.array([ 27 , 37 ])\n",
        "X[ 19 ]=np.array([ 32 , 22 ])\n",
        "X[ 20 ]=np.array([ 32 , 32 ])\n",
        "X[ 21 ]=np.array([ 32 , 37 ])\n",
        "X[ 22 ]=np.array([ 37 , 12 ])\n",
        "X[ 23 ]=np.array([ 37 , 17 ])\n",
        "X[ 24 ]=np.array([ 37 , 22 ])\n",
        "X[ 25 ]=np.array([ 37 , 27 ])\n",
        "X[ 26 ]=np.array([ 37 , 37 ])\n",
        "X[ 27 ]=np.array([ 42 , 22 ])\n",
        "X[ 28 ]=np.array([ 42 , 27 ])\n",
        "X[ 29 ]=np.array([ 42 , 32 ])\n",
        "X[ 30 ]=np.array([ 42 , 37 ])\n",
        "\n",
        "memoryofloss = collections.deque(maxlen=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgcbPga6afnv",
        "colab_type": "code",
        "outputId": "e46b1fbc-b0de-453b-8c92-1a34728654fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5408
        }
      },
      "source": [
        "for iteration in range(10):\n",
        "    loss = model.updateweights((X,Y))\n",
        "    memoryofloss.append(loss)\n",
        "print(sum(memoryofloss)/len(memoryofloss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "TODO\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUMmTmLGPAj",
        "colab_type": "text"
      },
      "source": [
        "**question bonus/alternative**\n",
        "\n",
        "Le méchanisme de rétro propagation du gradient permet de calculer le gradient vis à vis de l'entrée : cela permet de calculer comment il faudrait modifier un point pour qu'il soit mal classé !\n",
        "\n",
        "Taper *adversarial attack* dans google pour quelles illustrations.\n",
        "\n",
        "Faites un descente de gradient (en utilisant les objets torch) sur un point de la base pour l'amener hors de la zone correcte.\n",
        "\n",
        "\n",
        "*Cette question est conceptuellement plus compliqué que la précédente mais finalement moins compliquée en pratique*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1UeS0ZqH8ED",
        "colab_type": "code",
        "outputId": "b5ab4c0c-5cb8-4351-d993-40107239428a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TODO\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}